{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo nvTabular\n",
    "What follows is a demonstration of a lightweight re-imagining of the nvTabular library to show potential new conceptual relationships between objects. In doing so, I've tried to simplify code as much as possible following a few guiding principles:\n",
    "- writing python code is preferable to writing config files\n",
    "- an extra function call is preferable to a shim\n",
    "- explicit, and possibly longer, method and attribute names are preferable to shorthand\n",
    "- stateless objects are preferable to stateful ones\n",
    "    - as a corollary, use properties if you can\n",
    "- namedtuple inheriters are preferable to `__init__` methods that just save initialization arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nv_tabular as nvt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Schema\n",
    "We'll use some imaginary dataset I made to demonstrate the principles at work here. Note that we have two target labels, a common use case in recommendation systems for models like MMoE. Here we'll define the dataset **schema**, a high level description of the features the dataset uses and their type (continuous or categorical). This schema is conceptually distinct from any particular realization of this schema, e.g. the one found in `this_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['uid', 'iid', 'location', 'has_interacted_before']\n",
    "CONTINUOUS_COLUMNS = ['timestamp', 'user_age', 'item_average_rating']\n",
    "LABEL_COLUMNS = ['click', 'purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Workflow`\n",
    "A `Workflow` will represent this schema and a chain of transformations, or `Op`s, performed on it. Just as the schema is not tied to any particular realization of itself, neither are the transformations that get applied to it. The same `Workflow` should be able to be applied to one realization just as easily as another, provided they both can be fit into the appropriate schema.\n",
    "\n",
    "By default, the `Workflow` will be instantiated with no `Op`s in it, which for the sake of generality we can imagine as being initialized with just one op in its pipeline, the identity operation. We can add `Op`s to a workflow through a few methods, which we'll show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workflow = nvt.ops.Workflow(\n",
    "    cat_names=CATEGORICAL_COLUMNS,\n",
    "    cont_names=CONTINUOUS_COLUMNS,\n",
    "    label_names=LABEL_COLUMNS,\n",
    "    ops=[] # initialize with no ops\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`workflow` now represents a `Workflow` acting on the schema given by the designated columns. It can be applied to `Dataset`s that have _more_ columns than these, which it will drop, but any `Dataset` must contain these columns (we might adopt some language like it can apply to `Dataset`s with schema that are a **superset** of the `Workflow` schema, but not a **subset**).\n",
    "\n",
    "# Ops\n",
    "`Op`s are stateless representations of transforms that get applied to the schema in a `Workflow`. They can be instantiated by specifying columns on which to act, or can be left generic in order to apply to an entire category of variable (continuous of categorical) in *any* `Workflow` to which the `Op` is applied. In this case, what gets added to the `Workflow` is not the `Op` itself, but a copy of the `Op` with `columns` set to the corresponding group of columns in the `Workflow`.\n",
    "\n",
    "Alternatively, we can pass a function to `columns` that takes a column name as input and outputs a boolean indicating whether this `Op` should apply to such a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorify = nvt.ops.Categorify(columns=['uid', 'iid', 'location'], replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Op`s are operators acting on the existing `Workflow` schema, they are added to a `Workflow` by *calling* them on that `Workflow`, like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Categorify(columns=['uid', 'iid', 'location'], replace=True, name=None)]\n"
     ]
    }
   ],
   "source": [
    "workflow = categorify(workflow)\n",
    "print(workflow.ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the `Workflow` object itself inherits from `Op`, so we can add all the ops from one workflow to another by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "[Log(columns=[], replace=True, name=None), Normalize(columns=[], replace=True, name=None)]\n"
     ]
    }
   ],
   "source": [
    "log = nvt.ops.Log() # instantiate generically\n",
    "normalize = nvt.ops.Normalize()\n",
    "print(log.columns, normalize.columns)\n",
    "\n",
    "log_and_normalize_workflow = nvt.ops.Workflow(ops=[log, normalize]) # the whole workflow is being instantiate generically\n",
    "print(log_and_normalize_workflow.ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Categorify(columns=['uid', 'iid', 'location'], replace=True, name=None), Log(columns=['timestamp', 'user_age', 'item_average_rating'], replace=True, name=None), Normalize(columns=['timestamp', 'user_age', 'item_average_rating'], replace=True, name=None)]\n"
     ]
    }
   ],
   "source": [
    "workflow = log_and_normalize_workflow(workflow)\n",
    "print(workflow.ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that while the `Log` `Op` in our workflow has explicit columns now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'user_age', 'item_average_rating']\n"
     ]
    }
   ],
   "source": [
    "print(workflow.ops[1].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the original `Log` `Op` doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(log.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the same `Op` can be reused between different `Workflow`s without sacrificing its generality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "A `Dataset` object represents the file or files used in one realization of a dataset schema. It is an iterable object that iterates through that dataset in batches. This is probably the cheapest of my recreations here, but conceptually it should line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>location</th>\n",
       "      <th>has_interacted_before</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_age</th>\n",
       "      <th>item_average_rating</th>\n",
       "      <th>click</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qbdcpblvlt</td>\n",
       "      <td>58866</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0</td>\n",
       "      <td>1586992816</td>\n",
       "      <td>19</td>\n",
       "      <td>3.874372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atgapomeop</td>\n",
       "      <td>29207</td>\n",
       "      <td>Copenhagen</td>\n",
       "      <td>0</td>\n",
       "      <td>1587045716</td>\n",
       "      <td>39</td>\n",
       "      <td>4.417085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pmgfvettto</td>\n",
       "      <td>21504</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>1587003510</td>\n",
       "      <td>40</td>\n",
       "      <td>3.070352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lebsdtjdvx</td>\n",
       "      <td>33679</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1</td>\n",
       "      <td>1586976933</td>\n",
       "      <td>33</td>\n",
       "      <td>1.643216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>veuvxtfefp</td>\n",
       "      <td>94304</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1</td>\n",
       "      <td>1587054833</td>\n",
       "      <td>30</td>\n",
       "      <td>4.638191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>kltkhskjzo</td>\n",
       "      <td>3916</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>1587030892</td>\n",
       "      <td>28</td>\n",
       "      <td>4.698492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ejknasvbtb</td>\n",
       "      <td>44802</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>1</td>\n",
       "      <td>1587002114</td>\n",
       "      <td>38</td>\n",
       "      <td>2.849246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>oehgtxbklu</td>\n",
       "      <td>35596</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>1586982383</td>\n",
       "      <td>28</td>\n",
       "      <td>2.648241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ladbxduoqt</td>\n",
       "      <td>17234</td>\n",
       "      <td>Copenhagen</td>\n",
       "      <td>1</td>\n",
       "      <td>1586998553</td>\n",
       "      <td>20</td>\n",
       "      <td>3.110553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ozfqotbgpx</td>\n",
       "      <td>97818</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>1587020627</td>\n",
       "      <td>23</td>\n",
       "      <td>3.090452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uid    iid       location  has_interacted_before   timestamp  \\\n",
       "0    qbdcpblvlt  58866  San Francisco                      0  1586992816   \n",
       "1    atgapomeop  29207     Copenhagen                      0  1587045716   \n",
       "2    pmgfvettto  21504    Los Angeles                      0  1587003510   \n",
       "3    lebsdtjdvx  33679  San Francisco                      1  1586976933   \n",
       "4    veuvxtfefp  94304  San Francisco                      1  1587054833   \n",
       "..          ...    ...            ...                    ...         ...   \n",
       "123  kltkhskjzo   3916    Los Angeles                      0  1587030892   \n",
       "124  ejknasvbtb  44802       Berkeley                      1  1587002114   \n",
       "125  oehgtxbklu  35596    Los Angeles                      0  1586982383   \n",
       "126  ladbxduoqt  17234     Copenhagen                      1  1586998553   \n",
       "127  ozfqotbgpx  97818    Los Angeles                      1  1587020627   \n",
       "\n",
       "     user_age  item_average_rating  click  purchase  \n",
       "0          19             3.874372      0         1  \n",
       "1          39             4.417085      1         1  \n",
       "2          40             3.070352      1         0  \n",
       "3          33             1.643216      1         1  \n",
       "4          30             4.638191      0         0  \n",
       "..        ...                  ...    ...       ...  \n",
       "123        28             4.698492      1         0  \n",
       "124        38             2.849246      0         0  \n",
       "125        28             2.648241      1         1  \n",
       "126        20             3.110553      0         0  \n",
       "127        23             3.090452      1         0  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = nvt.dataset('this_data.csv', batch_size=128)\n",
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Context\n",
    "Some of the `Op`s in a `Workflow` may require statistics about a `Dataset` in order to be used. For example, the `Normalize` op above needs a feature-wise mean and standard deviation calculated from a `Dataset`, and the `Categorify` op needs to know all the categories used in a `Dataset` in order to map them to a contiguous integer. The `Stat`s required by an `Op` are available via its `stats_required` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<nv_tabular.stats.DLLabelEncoder object at 0x0000021B64F52F98>]\n"
     ]
    }
   ],
   "source": [
    "print(workflow.ops[0].stats_required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing is that a `Stat` is, in-and-of-itself, stateless: it represents the means by which to calculate an actual value given a `Dataset`, but not the value itself. It is not inherently *tied* to that value, in the same way that a dataset schema is not *tied* to a particular `Dataset`.\n",
    "\n",
    "The `StatsContext` object, on the other hand, is an object associated with a particular `Workflow` that maintains a state containing the actual values the `Workflow` can use. However, it is a distinct entity and the relationship is not bi-directional: while a `StatsContext` will be associated with *one* `Workflow`, which informs it which statistics it needs to calculate and maintain, a `Workflow` is agnostic to whatever `StatsContext` gets used during its `apply` method (assuming it has all the appropriate statistics associated with it). Let's see what this look like in code to clarify things a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berkeley         0\n",
      "Copenhagen       1\n",
      "Los Angeles      2\n",
      "San Francisco    3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "stats_context = nvt.stats.StatsContext(workflow)\n",
    "stats_context.fit(dataset)\n",
    "print(stats_context.state['categorify'][0]['location']['encoder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a workflow *and* the stats we need in order to apply it, we can map it to a dataset, which will apply the ops defined by `workflow` and parameterized by `stats_context` at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.map(workflow, stats_context=stats_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's nice about this formulation is that it decouples the dataset from the operations we want to apply to it, and vice versa, so that any `Workflow` can be recycled to apply to any new dataset that comes along, and can be used with statistics from any dataset we've fit a `StatsContext` to in the past. Meanwhile, any dataset can be remapped to apply some reformulated `Workflow` with a totally different `StatsContext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agunny\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\agunny\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>location</th>\n",
       "      <th>has_interacted_before</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_age</th>\n",
       "      <th>item_average_rating</th>\n",
       "      <th>click</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.915828</td>\n",
       "      <td>-1.737907</td>\n",
       "      <td>0.759322</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.232985</td>\n",
       "      <td>1.005439</td>\n",
       "      <td>1.054142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481429</td>\n",
       "      <td>1.102022</td>\n",
       "      <td>0.236251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.561014</td>\n",
       "      <td>0.368152</td>\n",
       "      <td>-1.169607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.603313</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>1.163987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630838</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>1.193037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.538135</td>\n",
       "      <td>0.906346</td>\n",
       "      <td>0.068175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.339628</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>-0.096350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.682786</td>\n",
       "      <td>-1.542231</td>\n",
       "      <td>0.265505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>62</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213872</td>\n",
       "      <td>-1.009060</td>\n",
       "      <td>0.250926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  iid  location  has_interacted_before  timestamp  user_age  \\\n",
       "0     68   36         3                      0  -0.915828 -1.737907   \n",
       "1      3   17         1                      0   1.232985  1.005439   \n",
       "2     65   13         2                      0  -0.481429  1.102022   \n",
       "3     44   22         3                      1  -1.561014  0.368152   \n",
       "4     90   45         3                      1   1.603313  0.004558   \n",
       "..   ...  ...       ...                    ...        ...       ...   \n",
       "123   38    2         2                      0   0.630838 -0.258639   \n",
       "124   16   29         0                      1  -0.538135  0.906346   \n",
       "125   55   24         2                      0  -1.339628 -0.258639   \n",
       "126   41   10         1                      1  -0.682786 -1.542231   \n",
       "127   62   49         2                      1   0.213872 -1.009060   \n",
       "\n",
       "     item_average_rating  click  purchase  \n",
       "0               0.759322      0         1  \n",
       "1               1.054142      1         1  \n",
       "2               0.236251      1         0  \n",
       "3              -1.169607      1         1  \n",
       "4               1.163987      0         0  \n",
       "..                   ...    ...       ...  \n",
       "123             1.193037      1         0  \n",
       "124             0.068175      0         0  \n",
       "125            -0.096350      1         1  \n",
       "126             0.265505      0         0  \n",
       "127             0.250926      1         0  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writer\n",
    "Now that we have a `Dataset` and have defined some transformations that we'd like to apply to it, we need to decide what to do with it. One route is to apply those transformations online during model training, but if our `Op`s are complex enough, that may end up bottlenecking performance. If we're confident that the `Workflow` we've defined is sufficiently robust that we'd like to use it for multiple training runs, it might make sense to transform this `Dataset` up front, possibly with some shuffling, and save it to disk to be read by our training runs later, which then won't need to do any preprocessing.\n",
    "\n",
    "`Writer` objects are associated with a particular file pattern or location and save out transformed and shuffled `Dataset`s as parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = nvt.writer.Writer('this_data.parquet')\n",
    "# I won't actually write because I don't have a parquet engine locally\n",
    "# writer.write(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to apply our `Workflow` with the `StatsContext` we've just taken the time to compute online at training time? The fundamental Python objects on which these are built are very simple, and so we can use Python's `pickle` protocol to save them to disk and load them back in later to apply to any new dataset that comes our way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('workflow.pickle', 'wb') as f:\n",
    "    pickle.dump(workflow, f)\n",
    "with open('stats.pickle', 'wb') as f:\n",
    "    pickle.dump(stats_context, f)\n",
    "del workflow, stats_context, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>location</th>\n",
       "      <th>has_interacted_before</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_age</th>\n",
       "      <th>item_average_rating</th>\n",
       "      <th>click</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.915828</td>\n",
       "      <td>-1.737907</td>\n",
       "      <td>0.759322</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.232985</td>\n",
       "      <td>1.005439</td>\n",
       "      <td>1.054142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481429</td>\n",
       "      <td>1.102022</td>\n",
       "      <td>0.236251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.561014</td>\n",
       "      <td>0.368152</td>\n",
       "      <td>-1.169607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.603313</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>1.163987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630838</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>1.193037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.538135</td>\n",
       "      <td>0.906346</td>\n",
       "      <td>0.068175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.339628</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>-0.096350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.682786</td>\n",
       "      <td>-1.542231</td>\n",
       "      <td>0.265505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>62</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213872</td>\n",
       "      <td>-1.009060</td>\n",
       "      <td>0.250926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  iid  location  has_interacted_before  timestamp  user_age  \\\n",
       "0     68   36         3                      0  -0.915828 -1.737907   \n",
       "1      3   17         1                      0   1.232985  1.005439   \n",
       "2     65   13         2                      0  -0.481429  1.102022   \n",
       "3     44   22         3                      1  -1.561014  0.368152   \n",
       "4     90   45         3                      1   1.603313  0.004558   \n",
       "..   ...  ...       ...                    ...        ...       ...   \n",
       "123   38    2         2                      0   0.630838 -0.258639   \n",
       "124   16   29         0                      1  -0.538135  0.906346   \n",
       "125   55   24         2                      0  -1.339628 -0.258639   \n",
       "126   41   10         1                      1  -0.682786 -1.542231   \n",
       "127   62   49         2                      1   0.213872 -1.009060   \n",
       "\n",
       "     item_average_rating  click  purchase  \n",
       "0               0.759322      0         1  \n",
       "1               1.054142      1         1  \n",
       "2               0.236251      1         0  \n",
       "3              -1.169607      1         1  \n",
       "4               1.163987      0         0  \n",
       "..                   ...    ...       ...  \n",
       "123             1.193037      1         0  \n",
       "124             0.068175      0         0  \n",
       "125            -0.096350      1         1  \n",
       "126             0.265505      0         0  \n",
       "127             0.250926      1         0  \n",
       "\n",
       "[128 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('workflow.pickle', 'rb') as f:\n",
    "    workflow = pickle.load(f)\n",
    "with open('stats.pickle', 'rb') as f:\n",
    "    stats_context = pickle.load(f)\n",
    "\n",
    "dataset = nvt.dataset('this_data.csv', batch_size=128)\n",
    "dataset.map(workflow, stats_context=stats_context)\n",
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Together Now\n",
    "Let's run that back in one place to see how this code looks all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nv_tabular as nvt\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['uid', 'iid', 'location', 'has_interacted_before']\n",
    "CONTINUOUS_COLUMNS = ['timestamp', 'user_age', 'item_average_rating']\n",
    "LABEL_COLUMNS = ['click', 'purchase']\n",
    "\n",
    "workflow = nvt.ops.Workflow(\n",
    "    cat_names=CATEGORICAL_COLUMNS,\n",
    "    cont_names=CONTINUOUS_COLUMNS,\n",
    "    label_names=LABEL_COLUMNS,\n",
    "    ops=[nvt.ops.Categorify(columns=['uid', 'iid', 'location'], replace=True)]\n",
    ")\n",
    "\n",
    "log_and_normalize_workflow = nvt.ops.Workflow(ops=[nvt.ops.Log(), nvt.ops.Normalize()])\n",
    "workflow = log_and_normalize_workflow(workflow)\n",
    "\n",
    "dataset = nvt.dataset('this_data.csv', batch_size=128)\n",
    "stats_context = nvt.stats.StatsContext(workflow)\n",
    "stats_context.fit(dataset)\n",
    "dataset.map(workflow, stats_context=stats_context)\n",
    "\n",
    "writer = nvt.writer.Writer('this_data.parquet')\n",
    "# writer.write(dataset)\n",
    "\n",
    "with open('workflow.pickle', 'wb') as f:\n",
    "    pickle.dump(workflow, f)\n",
    "with open('stats.pickle', 'wb') as f:\n",
    "    pickle.dump(stats_context, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
